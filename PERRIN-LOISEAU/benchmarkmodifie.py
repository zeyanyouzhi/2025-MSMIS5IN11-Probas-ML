import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, recall_score, confusion_matrix

# --- 1. CHARGEMENT DES DONN√âES ---
# (M√™me m√©thode manuelle que cancer_trainer.py pour la coh√©rence)
print("Chargement et pr√©paration des donn√©es...")

X_train = np.array([[float(j) for j in i.rstrip().split(",")] 
                    for i in open("train.csv").readlines()])
Y_train = X_train[:,-1]
X_train = X_train[:,0:-1]

X_test = np.array([[float(j) for j in i.rstrip().split(",")] 
                   for i in open("test.csv").readlines()])
Y_test = X_test[:,-1]
X_test = X_test[:,0:-1]

# --- 2. D√âFINITION DES 3 CHALLENGERS ---

# A. Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# B. SVM (Le favori pour la s√©curit√©)
svm = SVC(kernel='linear', random_state=42)

# C. Deep Learning (Ton r√©seau de neurones - Version Scikit-Learn)
# hidden_layer_sizes=(64, 64) correspond √† tes 2 couches de 64 neurones
dl = MLPClassifier(hidden_layer_sizes=(64, 64), activation='relu', max_iter=1000, random_state=42)

# --- 3. BOUCLE DE TEST UNIQUE ---
# On met les mod√®les dans une liste pour les tester un par un proprement
modeles = [
    ("Random Forest", rf),
    ("SVM (Classique)", svm),
    ("Deep Learning (MLP)", dl)
]

for nom, modele in modeles:
    print(f"\n‚è≥ Entra√Ænement de : {nom}...")
    modele.fit(X_train, Y_train)
    y_pred = modele.predict(X_test)
    
    # Calcul des scores
    acc = accuracy_score(Y_test, y_pred)
    rec = recall_score(Y_test, y_pred)
    cm = confusion_matrix(Y_test, y_pred)
    faux_negatifs = cm[1][0] # Le chiffre le plus important !
    
    # Affichage unique
    print(f"üìä R√âSULTATS : {nom}")
    print(f"   > Pr√©cision (Accuracy) : {acc*100:.2f}%")
    print(f"   > Rappel (S√©curit√©)    : {rec*100:.2f}%")
    print(f"   > Faux N√©gatifs        : {faux_negatifs} (Malades non d√©tect√©s)")
    print("-" * 30)